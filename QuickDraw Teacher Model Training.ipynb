{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dlagu\\anaconda3\\envs\\embed\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 40000\n",
      "Test set size: 10000\n",
      "Class circle: Train=4000, Test=1000\n",
      "Class triangle: Train=4000, Test=1000\n",
      "Class square: Train=4000, Test=1000\n",
      "Class donut: Train=4000, Test=1000\n",
      "Class house: Train=4000, Test=1000\n",
      "Class cloud: Train=4000, Test=1000\n",
      "Class lightning: Train=4000, Test=1000\n",
      "Class star: Train=4000, Test=1000\n",
      "Class diamond: Train=4000, Test=1000\n",
      "Class banana: Train=4000, Test=1000\n",
      "Batch images shape: torch.Size([64, 1, 32, 32])\n",
      "Batch labels shape: torch.Size([64])\n",
      "Labels in batch: tensor([0, 5, 7, 2, 2, 6, 3, 3, 2, 6, 0, 1, 0, 1, 4, 1, 7, 4, 2, 4, 1, 7, 3, 7,\n",
      "        4, 7, 4, 9, 5, 8, 6, 7, 8, 7, 6, 2, 8, 5, 5, 6, 2, 9, 2, 9, 0, 3, 9, 8,\n",
      "        2, 0, 1, 1, 4, 2, 3, 3, 7, 8, 7, 4, 2, 8, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "class QuickDrawDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None, augment=False):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def add_noise(self, image, noise_factor=0.1):\n",
    "        \"\"\"가우시안 노이즈 추가\"\"\"\n",
    "        noise = torch.randn_like(image) * noise_factor\n",
    "        noisy_image = image + noise\n",
    "        return torch.clamp(noisy_image, 0., 1.)\n",
    "\n",
    "    def add_occlusion(self, image, block_size=4, num_blocks=4):\n",
    "        \"\"\"랜덤 위치에 사각형 영역을 0으로 설정하여 occlusion 효과 생성\"\"\"\n",
    "        img = image.clone()\n",
    "        h, w = img.shape[1:]\n",
    "        \n",
    "        for _ in range(num_blocks):\n",
    "            # 랜덤 위치 선택\n",
    "            x = random.randint(0, w - block_size)\n",
    "            y = random.randint(0, h - block_size)\n",
    "            \n",
    "            # 해당 영역을 0으로 설정\n",
    "            img[:, y:y+block_size, x:x+block_size] = 0\n",
    "            \n",
    "        return img\n",
    "\n",
    "    def elastic_transform(self, image, alpha=500, sigma=20, random_state=None):\n",
    "        \"\"\"Elastic deformation for simulating natural drawing variations\"\"\"\n",
    "        if random_state is None:\n",
    "            random_state = np.random.RandomState(None)\n",
    "\n",
    "        shape = image.shape[1:]\n",
    "        dx = torch.tensor(random_state.rand(*shape) * 2 - 1)\n",
    "        dy = torch.tensor(random_state.rand(*shape) * 2 - 1)\n",
    "\n",
    "        # Gaussian filter\n",
    "        dx = F.gaussian_blur(dx.unsqueeze(0).unsqueeze(0), kernel_size=7, sigma=sigma).squeeze()\n",
    "        dy = F.gaussian_blur(dy.unsqueeze(0).unsqueeze(0), kernel_size=7, sigma=sigma).squeeze()\n",
    "\n",
    "        # Normalize and scale\n",
    "        dx = dx * alpha / (sigma * shape[0])\n",
    "        dy = dy * alpha / (sigma * shape[1])\n",
    "\n",
    "        # Create meshgrid\n",
    "        x, y = torch.meshgrid(torch.arange(shape[0]), torch.arange(shape[1]))\n",
    "        \n",
    "        # Add displacement\n",
    "        indices_x = torch.clamp(x + dx, 0, shape[0] - 1).long()\n",
    "        indices_y = torch.clamp(y + dy, 0, shape[1] - 1).long()\n",
    "\n",
    "        # Apply transformation\n",
    "        transformed = image.clone()\n",
    "        transformed[0] = image[0][indices_x, indices_y]\n",
    "        \n",
    "        return transformed\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # 이미지를 텐서로 변환하고 채널 차원 추가\n",
    "        image = torch.FloatTensor(image).unsqueeze(0)\n",
    "        \n",
    "        # Data augmentation 적용\n",
    "        if self.augment:\n",
    "            # 랜덤하게 augmentation 적용\n",
    "            if random.random() < 0.3:  # 30% 확률로 노이즈 추가\n",
    "                image = self.add_noise(image, noise_factor=0.1)\n",
    "            \n",
    "            if random.random() < 0.3:  # 30% 확률로 occlusion 추가\n",
    "                image = self.add_occlusion(image, block_size=4, num_blocks=random.randint(1, 3))\n",
    "            \n",
    "            if random.random() < 0.3:  # 30% 확률로 elastic transform 적용\n",
    "                image = self.elastic_transform(image, alpha=random.randint(300, 700))\n",
    "            \n",
    "            # 랜덤 회전 (-15도 ~ 15도)\n",
    "            if random.random() < 0.3:\n",
    "                angle = random.uniform(-15, 15)\n",
    "                image = F.rotate(image, angle)\n",
    "\n",
    "        # 추가 transform이 있다면 적용\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # 레이블을 Long 타입으로 변환\n",
    "        label = torch.LongTensor([label])[0]\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "def create_dataloaders(npz_path, batch_size=64, test_size=0.2):\n",
    "    \"\"\"데이터 로더 생성 함수\"\"\"\n",
    "    # 데이터 로드\n",
    "    data = np.load(npz_path)\n",
    "    images = data['data'].astype(np.float32) / 255.0  # 정규화\n",
    "    labels = data['labels']\n",
    "    \n",
    "    # Train/Test 분할\n",
    "    num_samples = len(images)\n",
    "    indices = np.random.permutation(num_samples)\n",
    "    split = int(np.floor(test_size * num_samples))\n",
    "    \n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    \n",
    "    # Dataset 생성\n",
    "    train_dataset = QuickDrawDataset(\n",
    "        images[train_idx], \n",
    "        labels[train_idx],\n",
    "        augment=True  # training set에만 augmentation 적용\n",
    "    )\n",
    "    \n",
    "    test_dataset = QuickDrawDataset(\n",
    "        images[test_idx],\n",
    "        labels[test_idx],\n",
    "        augment=False  # test set에는 augmentation 미적용\n",
    "    )\n",
    "    \n",
    "    # DataLoader 생성\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# 데이터 로드 및 전처리 함수\n",
    "def prepare_data(npz_path, test_size=0.2):\n",
    "    # 데이터 로드\n",
    "    data = np.load(npz_path)\n",
    "    images = data['data']\n",
    "    labels = data['labels']\n",
    "    classes = data['classes']\n",
    "    \n",
    "    # 클래스별로 데이터 분리\n",
    "    X_train, X_test = [], []\n",
    "    y_train, y_test = [], []\n",
    "    \n",
    "    for class_idx in range(len(classes)):\n",
    "        # 현재 클래스의 데이터 인덱스 찾기\n",
    "        class_indices = np.where(labels == class_idx)[0]\n",
    "        class_images = images[class_indices]\n",
    "        class_labels = labels[class_indices]\n",
    "        \n",
    "        # 현재 클래스의 데이터를 train/test로 분할\n",
    "        X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
    "            class_images, class_labels, test_size=test_size, random_state=42\n",
    "        )\n",
    "        \n",
    "        X_train.append(X_train_class)\n",
    "        X_test.append(X_test_class)\n",
    "        y_train.append(y_train_class)\n",
    "        y_test.append(y_test_class)\n",
    "    \n",
    "    # 모든 클래스의 데이터 합치기\n",
    "    X_train = np.concatenate(X_train, axis=0)\n",
    "    X_test = np.concatenate(X_test, axis=0)\n",
    "    y_train = np.concatenate(y_train, axis=0)\n",
    "    y_test = np.concatenate(y_test, axis=0)\n",
    "    \n",
    "    print(f\"Training set size: {len(X_train)}\")\n",
    "    print(f\"Test set size: {len(X_test)}\")\n",
    "    \n",
    "    # 클래스별 분포 확인\n",
    "    for i in range(len(classes)):\n",
    "        train_count = np.sum(y_train == i)\n",
    "        test_count = np.sum(y_test == i)\n",
    "        print(f\"Class {classes[i]}: Train={train_count}, Test={test_count}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, classes\n",
    "\n",
    "# 데이터 준비\n",
    "X_train, X_test, y_train, y_test, classes = prepare_data('quickdraw_dataset.npz')\n",
    "\n",
    "# 데이터 변환 정의\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.RandomErasing(p=0.2),\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_dataset = QuickDrawDataset(X_train, y_train, transform=train_transform)\n",
    "test_dataset = QuickDrawDataset(X_test, y_test, transform=test_transform)\n",
    "\n",
    "# 데이터 로더 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "# 데이터 형태 확인\n",
    "for images, labels in train_loader:\n",
    "    print(f\"Batch images shape: {images.shape}\")\n",
    "    print(f\"Batch labels shape: {labels.shape}\")\n",
    "    print(f\"Labels in batch: {labels}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherVGG(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(TeacherVGG, self).__init__()\n",
    "        \n",
    "        # 입력: 1채널 (흑백)\n",
    "        self.features = nn.Sequential(\n",
    "            # 첫 번째 블록\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # 두 번째 블록\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # 세 번째 블록\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        \n",
    "        # 분류기\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((4, 4)),  # 가변적인 입력 크기 처리\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 4 * 4, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "# 모델 생성\n",
    "model = TeacherVGG(num_classes=len(classes)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 625/625 [00:38<00:00, 16.44it/s, loss=0.2676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.4575, Accuracy = 94.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 625/625 [00:34<00:00, 18.01it/s, loss=0.1956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss = 0.2927, Accuracy = 95.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 625/625 [00:33<00:00, 18.39it/s, loss=0.4629]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss = 0.2536, Accuracy = 95.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 625/625 [00:33<00:00, 18.54it/s, loss=0.1276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss = 0.2420, Accuracy = 95.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 625/625 [00:33<00:00, 18.56it/s, loss=0.1175]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss = 0.2264, Accuracy = 95.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 625/625 [00:33<00:00, 18.54it/s, loss=0.0811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss = 0.2038, Accuracy = 95.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 625/625 [00:34<00:00, 17.89it/s, loss=0.3752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss = 0.1998, Accuracy = 96.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 625/625 [00:35<00:00, 17.45it/s, loss=0.2341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss = 0.1921, Accuracy = 96.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 625/625 [00:34<00:00, 17.90it/s, loss=0.1216]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss = 0.1819, Accuracy = 96.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 625/625 [00:35<00:00, 17.69it/s, loss=0.4419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss = 0.1780, Accuracy = 96.53%\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    best_acc = 0.0\n",
    "    train_losses = []\n",
    "    test_accs = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # 학습\n",
    "        with tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}') as pbar:\n",
    "            for inputs, labels in pbar:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        # 평가\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        accuracy = 100. * correct / total\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "        test_accs.append(accuracy)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: Loss = {running_loss/len(train_loader):.4f}, '\n",
    "              f'Accuracy = {accuracy:.2f}%')\n",
    "        \n",
    "        # 모델 저장\n",
    "        if accuracy > best_acc:\n",
    "            best_acc = accuracy\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'accuracy': accuracy,\n",
    "            }, 'best_teacher_model.pth')\n",
    "        \n",
    "        scheduler.step(accuracy)\n",
    "    \n",
    "    return train_losses, test_accs\n",
    "\n",
    "# 손실 함수, 최적화기, 스케줄러 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
    "\n",
    "# 모델 학습\n",
    "train_losses, test_accs = train_model(model, train_loader, test_loader, \n",
    "                                    criterion, optimizer, scheduler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
